{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HLS Foundation Model Fine-Tuning Guide\n",
        "\n",
        "This notebook is designed to offer a guideline for fine-tuning semantic segmentation models using the [HLS Prithvi model](https://github.com/NASA-IMPACT/hls-foundation-os). To run this notebook, you will need a few resources:\n",
        "\n",
        "1. The HLS Prithvi model weights, which can be found [here](https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M). We recommend downloading this to Google Drive.\n",
        "\n",
        "2. A segmentation dataset which you can generate by following [this guide](https://colab.research.google.com/drive/1VEJOpyeTJeYSX8EcINe1m7lA-Bi7YoqU?usp=sharing).\n",
        "\n",
        "3. A configuration file which you can define using [this guide](https://colab.research.google.com/drive/1cOU_JG73dsLmAx4B9yr3tmTvflx0AJ9I?usp=sharing)."
      ],
      "metadata": {
        "id": "VX5RusnTZ_qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Google Drive to access the config file and training/validation training set."
      ],
      "metadata": {
        "id": "ocJcJ11OmMpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66HvXRAyHrOR",
        "outputId": "8f1affe3-48c3-478c-8364-ffbabffd5e22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download all of the dependencies including cloning the HLS Foundation Model github repo."
      ],
      "metadata": {
        "id": "MWLo5pHAmjpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "!pip install torch==1.11.0+cu115 torchvision==0.12.0+cu115 --extra-index-url https://download.pytorch.org/whl/cu115\n",
        "!git clone https://github.com/NASA-IMPACT/hls-foundation-os.git\n",
        "os.chdir('/content/hls-foundation-os')\n",
        "!pip install -e .\n",
        "!pip install -U openmim\n",
        "!mim install mmcv-full==1.6.2 -f https://download.openmmlab.com/mmcv/dist/cu115/torch1.11.0/index.html\n",
        "!pip install yapf==0.40.1\n",
        "import torch\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "WJBecA1nbq22"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Specify the config file path"
      ],
      "metadata": {
        "id": "3JUSa2Stwt4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Config file path\n",
        "config_file_path = \"/content/gdrive/MyDrive/HLS foundation guide/hls_config.py\"\n",
        "config_file_path = f'\"{config_file_path}\"'"
      ],
      "metadata": {
        "id": "un2RGvqBm0JE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fine-Tuning\n",
        "Run the command below to begin fine-tuning. The config file defines all of the important meta-parameters for training, as well as the storage location of the dataset. The log files and model checkpoints will be saved in the experiment file path defined within the config file."
      ],
      "metadata": {
        "id": "Pvkj4EzBgxgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mim train mmsegmentation --launcher pytorch {config_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HakqG-JdVIYO",
        "outputId": "0ade1367-39bf-4f84-a8de-11dfdd4fc8a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using port 24023 for synchronization. \n",
            "Training command is /usr/bin/python3 -m torch.distributed.launch --nproc_per_node=1 --master_port=24023 /usr/local/lib/python3.10/dist-packages/mmseg/.mim/tools/train.py /content/gdrive/MyDrive/HLS foundation guide/hls_config.py --launcher pytorch. \n",
            "/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2023-10-24 17:51:08,516 - mmseg - INFO - Multi-processing start method is `None`\n",
            "2023-10-24 17:51:08,518 - mmseg - INFO - OpenCV num_threads is `2\n",
            "2023-10-24 17:51:08,567 - mmseg - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "CUDA available: True\n",
            "GPU 0: Tesla T4\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "PyTorch: 1.11.0+cu115\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.5\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.3.2\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.5, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "TorchVision: 0.12.0+cu115\n",
            "OpenCV: 4.8.0\n",
            "MMCV: 1.6.2\n",
            "MMCV Compiler: GCC 9.3\n",
            "MMCV CUDA Compiler: 11.5\n",
            "MMSegmentation: 0.30.0+4757c74\n",
            "------------------------------------------------------------\n",
            "\n",
            "2023-10-24 17:51:08,567 - mmseg - INFO - Distributed training: True\n",
            "2023-10-24 17:51:09,358 - mmseg - INFO - Config:\n",
            "custom_imports = dict(imports=['geospatial_fm'])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "cudnn_benchmark = True\n",
            "dataset_type = 'GeospatialDataset'\n",
            "data_root = '/content/gdrive/MyDrive/HLS foundation guide/dataset'\n",
            "num_frames = 1\n",
            "img_size = 224\n",
            "num_workers = 4\n",
            "samples_per_gpu = 4\n",
            "img_norm_cfg = dict(\n",
            "    means=[\n",
            "        0.08285756, 0.09015894, 0.14294316, 0.26300612, 0.25897524, 0.21503\n",
            "    ],\n",
            "    stds=[\n",
            "        0.03269446, 0.03606708, 0.04953382, 0.07931096, 0.06092547, 0.05726682\n",
            "    ])\n",
            "bands = [0, 1, 2, 3, 4, 5]\n",
            "img_suffix = '_tile.tif'\n",
            "seg_map_suffix = '_mask.tif'\n",
            "orig_nsize = 256\n",
            "tile_size = 224\n",
            "crop_size = (224, 224)\n",
            "ignore_index = -1\n",
            "image_nodata = -9999\n",
            "image_nodata_replace = 0\n",
            "image_to_float32 = True\n",
            "experiment = 'HLS_wellpad_finetuning'\n",
            "project_dir = '/content/gdrive/MyDrive/HLS foundation guide'\n",
            "work_dir = '/content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning'\n",
            "save_path = '/content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning'\n",
            "pretrained_weights_path = '/content/gdrive/MyDrive/HLS Foundation Model/Prithvi_100M.pt'\n",
            "epochs = 5\n",
            "eval_epoch_interval = 1\n",
            "num_layers = 12\n",
            "patch_size = 16\n",
            "embed_dim = 768\n",
            "num_heads = 12\n",
            "tubelet_size = 1\n",
            "output_embed_dim = 768\n",
            "train_pipeline = [\n",
            "    dict(type='LoadGeospatialImageFromFile', to_float32=True),\n",
            "    dict(type='LoadGeospatialAnnotations', reduce_zero_label=False),\n",
            "    dict(type='BandsExtract', bands=[0, 1, 2, 3, 4, 5]),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(type='ToTensor', keys=['img', 'gt_semantic_seg']),\n",
            "    dict(type='TorchPermute', keys=['img'], order=(2, 0, 1)),\n",
            "    dict(\n",
            "        type='TorchNormalize',\n",
            "        means=[\n",
            "            0.08285756, 0.09015894, 0.14294316, 0.26300612, 0.25897524, 0.21503\n",
            "        ],\n",
            "        stds=[\n",
            "            0.03269446, 0.03606708, 0.04953382, 0.07931096, 0.06092547,\n",
            "            0.05726682\n",
            "        ]),\n",
            "    dict(type='TorchRandomCrop', crop_size=(224, 224)),\n",
            "    dict(type='Reshape', keys=['img'], new_shape=(6, 1, 224, 224)),\n",
            "    dict(type='Reshape', keys=['gt_semantic_seg'], new_shape=(1, 224, 224)),\n",
            "    dict(\n",
            "        type='CastTensor',\n",
            "        keys=['gt_semantic_seg'],\n",
            "        new_type='torch.LongTensor'),\n",
            "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadGeospatialImageFromFile', to_float32=True),\n",
            "    dict(type='BandsExtract', bands=[0, 1, 2, 3, 4, 5]),\n",
            "    dict(type='ToTensor', keys=['img']),\n",
            "    dict(type='TorchPermute', keys=['img'], order=(2, 0, 1)),\n",
            "    dict(\n",
            "        type='TorchNormalize',\n",
            "        means=[\n",
            "            0.08285756, 0.09015894, 0.14294316, 0.26300612, 0.25897524, 0.21503\n",
            "        ],\n",
            "        stds=[\n",
            "            0.03269446, 0.03606708, 0.04953382, 0.07931096, 0.06092547,\n",
            "            0.05726682\n",
            "        ]),\n",
            "    dict(\n",
            "        type='Reshape',\n",
            "        keys=['img'],\n",
            "        new_shape=(6, 1, -1, -1),\n",
            "        look_up=dict({\n",
            "            '2': 1,\n",
            "            '3': 2\n",
            "        })),\n",
            "    dict(type='CastTensor', keys=['img'], new_type='torch.FloatTensor'),\n",
            "    dict(\n",
            "        type='CollectTestList',\n",
            "        keys=['img'],\n",
            "        meta_keys=[\n",
            "            'img_info', 'seg_fields', 'img_prefix', 'seg_prefix', 'filename',\n",
            "            'ori_filename', 'img', 'img_shape', 'ori_shape', 'pad_shape',\n",
            "            'scale_factor', 'img_norm_cfg'\n",
            "        ])\n",
            "]\n",
            "CLASSES = ('Not Well Pad', 'Well Pad')\n",
            "data = dict(\n",
            "    samples_per_gpu=4,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='GeospatialDataset',\n",
            "        CLASSES=('Not Well Pad', 'Well Pad'),\n",
            "        data_root='/content/gdrive/MyDrive/HLS foundation guide/dataset',\n",
            "        img_dir='training',\n",
            "        ann_dir='training',\n",
            "        img_suffix='_tile.tif',\n",
            "        seg_map_suffix='_mask.tif',\n",
            "        pipeline=[\n",
            "            dict(type='LoadGeospatialImageFromFile', to_float32=True),\n",
            "            dict(type='LoadGeospatialAnnotations', reduce_zero_label=False),\n",
            "            dict(type='BandsExtract', bands=[0, 1, 2, 3, 4, 5]),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(type='ToTensor', keys=['img', 'gt_semantic_seg']),\n",
            "            dict(type='TorchPermute', keys=['img'], order=(2, 0, 1)),\n",
            "            dict(\n",
            "                type='TorchNormalize',\n",
            "                means=[\n",
            "                    0.08285756, 0.09015894, 0.14294316, 0.26300612, 0.25897524,\n",
            "                    0.21503\n",
            "                ],\n",
            "                stds=[\n",
            "                    0.03269446, 0.03606708, 0.04953382, 0.07931096, 0.06092547,\n",
            "                    0.05726682\n",
            "                ]),\n",
            "            dict(type='TorchRandomCrop', crop_size=(224, 224)),\n",
            "            dict(type='Reshape', keys=['img'], new_shape=(6, 1, 224, 224)),\n",
            "            dict(\n",
            "                type='Reshape',\n",
            "                keys=['gt_semantic_seg'],\n",
            "                new_shape=(1, 224, 224)),\n",
            "            dict(\n",
            "                type='CastTensor',\n",
            "                keys=['gt_semantic_seg'],\n",
            "                new_type='torch.LongTensor'),\n",
            "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
            "        ],\n",
            "        ignore_index=-1),\n",
            "    val=dict(\n",
            "        type='GeospatialDataset',\n",
            "        CLASSES=('Not Well Pad', 'Well Pad'),\n",
            "        data_root='/content/gdrive/MyDrive/HLS foundation guide/dataset',\n",
            "        img_dir='validation',\n",
            "        ann_dir='validation',\n",
            "        img_suffix='_tile.tif',\n",
            "        seg_map_suffix='_mask.tif',\n",
            "        pipeline=[\n",
            "            dict(type='LoadGeospatialImageFromFile', to_float32=True),\n",
            "            dict(type='BandsExtract', bands=[0, 1, 2, 3, 4, 5]),\n",
            "            dict(type='ToTensor', keys=['img']),\n",
            "            dict(type='TorchPermute', keys=['img'], order=(2, 0, 1)),\n",
            "            dict(\n",
            "                type='TorchNormalize',\n",
            "                means=[\n",
            "                    0.08285756, 0.09015894, 0.14294316, 0.26300612, 0.25897524,\n",
            "                    0.21503\n",
            "                ],\n",
            "                stds=[\n",
            "                    0.03269446, 0.03606708, 0.04953382, 0.07931096, 0.06092547,\n",
            "                    0.05726682\n",
            "                ]),\n",
            "            dict(\n",
            "                type='Reshape',\n",
            "                keys=['img'],\n",
            "                new_shape=(6, 1, -1, -1),\n",
            "                look_up=dict({\n",
            "                    '2': 1,\n",
            "                    '3': 2\n",
            "                })),\n",
            "            dict(\n",
            "                type='CastTensor', keys=['img'], new_type='torch.FloatTensor'),\n",
            "            dict(\n",
            "                type='CollectTestList',\n",
            "                keys=['img'],\n",
            "                meta_keys=[\n",
            "                    'img_info', 'seg_fields', 'img_prefix', 'seg_prefix',\n",
            "                    'filename', 'ori_filename', 'img', 'img_shape',\n",
            "                    'ori_shape', 'pad_shape', 'scale_factor', 'img_norm_cfg'\n",
            "                ])\n",
            "        ],\n",
            "        ignore_index=-1),\n",
            "    test=dict(\n",
            "        type='GeospatialDataset',\n",
            "        CLASSES=('Not Well Pad', 'Well Pad'),\n",
            "        data_root='/content/gdrive/MyDrive/HLS foundation guide/dataset',\n",
            "        img_dir='validation',\n",
            "        ann_dir='validation',\n",
            "        img_suffix='_tile.tif',\n",
            "        seg_map_suffix='_mask.tif',\n",
            "        pipeline=[\n",
            "            dict(type='LoadGeospatialImageFromFile', to_float32=True),\n",
            "            dict(type='BandsExtract', bands=[0, 1, 2, 3, 4, 5]),\n",
            "            dict(type='ToTensor', keys=['img']),\n",
            "            dict(type='TorchPermute', keys=['img'], order=(2, 0, 1)),\n",
            "            dict(\n",
            "                type='TorchNormalize',\n",
            "                means=[\n",
            "                    0.08285756, 0.09015894, 0.14294316, 0.26300612, 0.25897524,\n",
            "                    0.21503\n",
            "                ],\n",
            "                stds=[\n",
            "                    0.03269446, 0.03606708, 0.04953382, 0.07931096, 0.06092547,\n",
            "                    0.05726682\n",
            "                ]),\n",
            "            dict(\n",
            "                type='Reshape',\n",
            "                keys=['img'],\n",
            "                new_shape=(6, 1, -1, -1),\n",
            "                look_up=dict({\n",
            "                    '2': 1,\n",
            "                    '3': 2\n",
            "                })),\n",
            "            dict(\n",
            "                type='CastTensor', keys=['img'], new_type='torch.FloatTensor'),\n",
            "            dict(\n",
            "                type='CollectTestList',\n",
            "                keys=['img'],\n",
            "                meta_keys=[\n",
            "                    'img_info', 'seg_fields', 'img_prefix', 'seg_prefix',\n",
            "                    'filename', 'ori_filename', 'img', 'img_shape',\n",
            "                    'ori_shape', 'pad_shape', 'scale_factor', 'img_norm_cfg'\n",
            "                ])\n",
            "        ],\n",
            "        ignore_index=-1))\n",
            "optimizer = dict(type='Adam', lr=1.3e-05, betas=(0.9, 0.999))\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='poly',\n",
            "    warmup='linear',\n",
            "    warmup_iters=1500,\n",
            "    warmup_ratio=1e-06,\n",
            "    power=1.0,\n",
            "    min_lr=0.0,\n",
            "    by_epoch=False)\n",
            "log_config = dict(\n",
            "    interval=20,\n",
            "    hooks=[\n",
            "        dict(type='TextLoggerHook', by_epoch=False),\n",
            "        dict(type='TensorboardLoggerHook', by_epoch=False)\n",
            "    ])\n",
            "checkpoint_config = dict(\n",
            "    by_epoch=True,\n",
            "    interval=10,\n",
            "    out_dir=\n",
            "    '/content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning')\n",
            "evaluation = dict(\n",
            "    interval=1, metric='mIoU', pre_eval=True, save_best='mIoU', by_epoch=True)\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=5)\n",
            "loss_func = dict(\n",
            "    type='DiceLoss', use_sigmoid=False, loss_weight=1, ignore_index=-1)\n",
            "workflow = [('train', 1)]\n",
            "norm_cfg = dict(type='BN', requires_grad=True)\n",
            "model = dict(\n",
            "    type='TemporalEncoderDecoder',\n",
            "    frozen_backbone=False,\n",
            "    backbone=dict(\n",
            "        type='TemporalViTEncoder',\n",
            "        pretrained=\n",
            "        '/content/gdrive/MyDrive/HLS Foundation Model/Prithvi_100M.pt',\n",
            "        img_size=224,\n",
            "        patch_size=16,\n",
            "        num_frames=1,\n",
            "        tubelet_size=1,\n",
            "        in_chans=6,\n",
            "        embed_dim=768,\n",
            "        depth=12,\n",
            "        num_heads=12,\n",
            "        mlp_ratio=4.0,\n",
            "        norm_pix_loss=False),\n",
            "    neck=dict(\n",
            "        type='ConvTransformerTokensToEmbeddingNeck',\n",
            "        embed_dim=768,\n",
            "        output_embed_dim=768,\n",
            "        drop_cls_token=True,\n",
            "        Hp=14,\n",
            "        Wp=14),\n",
            "    decode_head=dict(\n",
            "        num_classes=2,\n",
            "        in_channels=768,\n",
            "        type='FCNHead',\n",
            "        in_index=-1,\n",
            "        channels=256,\n",
            "        num_convs=1,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        align_corners=False,\n",
            "        loss_decode=dict(\n",
            "            type='DiceLoss', use_sigmoid=False, loss_weight=1,\n",
            "            ignore_index=-1)),\n",
            "    auxiliary_head=dict(\n",
            "        num_classes=2,\n",
            "        in_channels=768,\n",
            "        type='FCNHead',\n",
            "        in_index=-1,\n",
            "        channels=256,\n",
            "        num_convs=2,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        align_corners=False,\n",
            "        loss_decode=dict(\n",
            "            type='DiceLoss', use_sigmoid=False, loss_weight=1,\n",
            "            ignore_index=-1)),\n",
            "    train_cfg=dict(),\n",
            "    test_cfg=dict(mode='slide', stride=(112, 112), crop_size=(224, 224)))\n",
            "gpu_ids = range(0, 1)\n",
            "auto_resume = False\n",
            "\n",
            "2023-10-24 17:51:09,428 - mmseg - INFO - Set random seed to 817450106, deterministic: False\n",
            "load from /content/gdrive/MyDrive/HLS Foundation Model/Prithvi_100M.pt\n",
            "load checkpoint from local path: /content/gdrive/MyDrive/HLS Foundation Model/Prithvi_100M.pt\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for pos_embed: copying a param with shape torch.Size([1, 589, 768]) from checkpoint, the shape in current model is torch.Size([1, 197, 768]).\n",
            "unexpected key in source state_dict: mask_token, decoder_pos_embed, decoder_embed.weight, decoder_embed.bias, decoder_blocks.0.norm1.weight, decoder_blocks.0.norm1.bias, decoder_blocks.0.attn.qkv.weight, decoder_blocks.0.attn.qkv.bias, decoder_blocks.0.attn.proj.weight, decoder_blocks.0.attn.proj.bias, decoder_blocks.0.norm2.weight, decoder_blocks.0.norm2.bias, decoder_blocks.0.mlp.fc1.weight, decoder_blocks.0.mlp.fc1.bias, decoder_blocks.0.mlp.fc2.weight, decoder_blocks.0.mlp.fc2.bias, decoder_blocks.1.norm1.weight, decoder_blocks.1.norm1.bias, decoder_blocks.1.attn.qkv.weight, decoder_blocks.1.attn.qkv.bias, decoder_blocks.1.attn.proj.weight, decoder_blocks.1.attn.proj.bias, decoder_blocks.1.norm2.weight, decoder_blocks.1.norm2.bias, decoder_blocks.1.mlp.fc1.weight, decoder_blocks.1.mlp.fc1.bias, decoder_blocks.1.mlp.fc2.weight, decoder_blocks.1.mlp.fc2.bias, decoder_blocks.2.norm1.weight, decoder_blocks.2.norm1.bias, decoder_blocks.2.attn.qkv.weight, decoder_blocks.2.attn.qkv.bias, decoder_blocks.2.attn.proj.weight, decoder_blocks.2.attn.proj.bias, decoder_blocks.2.norm2.weight, decoder_blocks.2.norm2.bias, decoder_blocks.2.mlp.fc1.weight, decoder_blocks.2.mlp.fc1.bias, decoder_blocks.2.mlp.fc2.weight, decoder_blocks.2.mlp.fc2.bias, decoder_blocks.3.norm1.weight, decoder_blocks.3.norm1.bias, decoder_blocks.3.attn.qkv.weight, decoder_blocks.3.attn.qkv.bias, decoder_blocks.3.attn.proj.weight, decoder_blocks.3.attn.proj.bias, decoder_blocks.3.norm2.weight, decoder_blocks.3.norm2.bias, decoder_blocks.3.mlp.fc1.weight, decoder_blocks.3.mlp.fc1.bias, decoder_blocks.3.mlp.fc2.weight, decoder_blocks.3.mlp.fc2.bias, decoder_blocks.4.norm1.weight, decoder_blocks.4.norm1.bias, decoder_blocks.4.attn.qkv.weight, decoder_blocks.4.attn.qkv.bias, decoder_blocks.4.attn.proj.weight, decoder_blocks.4.attn.proj.bias, decoder_blocks.4.norm2.weight, decoder_blocks.4.norm2.bias, decoder_blocks.4.mlp.fc1.weight, decoder_blocks.4.mlp.fc1.bias, decoder_blocks.4.mlp.fc2.weight, decoder_blocks.4.mlp.fc2.bias, decoder_blocks.5.norm1.weight, decoder_blocks.5.norm1.bias, decoder_blocks.5.attn.qkv.weight, decoder_blocks.5.attn.qkv.bias, decoder_blocks.5.attn.proj.weight, decoder_blocks.5.attn.proj.bias, decoder_blocks.5.norm2.weight, decoder_blocks.5.norm2.bias, decoder_blocks.5.mlp.fc1.weight, decoder_blocks.5.mlp.fc1.bias, decoder_blocks.5.mlp.fc2.weight, decoder_blocks.5.mlp.fc2.bias, decoder_blocks.6.norm1.weight, decoder_blocks.6.norm1.bias, decoder_blocks.6.attn.qkv.weight, decoder_blocks.6.attn.qkv.bias, decoder_blocks.6.attn.proj.weight, decoder_blocks.6.attn.proj.bias, decoder_blocks.6.norm2.weight, decoder_blocks.6.norm2.bias, decoder_blocks.6.mlp.fc1.weight, decoder_blocks.6.mlp.fc1.bias, decoder_blocks.6.mlp.fc2.weight, decoder_blocks.6.mlp.fc2.bias, decoder_blocks.7.norm1.weight, decoder_blocks.7.norm1.bias, decoder_blocks.7.attn.qkv.weight, decoder_blocks.7.attn.qkv.bias, decoder_blocks.7.attn.proj.weight, decoder_blocks.7.attn.proj.bias, decoder_blocks.7.norm2.weight, decoder_blocks.7.norm2.bias, decoder_blocks.7.mlp.fc1.weight, decoder_blocks.7.mlp.fc1.bias, decoder_blocks.7.mlp.fc2.weight, decoder_blocks.7.mlp.fc2.bias, decoder_norm.weight, decoder_norm.bias, decoder_pred.weight, decoder_pred.bias\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/mmseg/models/decode_heads/decode_head.py:104: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "2023-10-24 17:51:11,697 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "2023-10-24 17:51:11,699 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "2023-10-24 17:51:11,703 - mmseg - INFO - TemporalEncoderDecoder(\n",
            "  (backbone): TemporalViTEncoder(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (proj): Conv3d(6, 768, kernel_size=(1, 16, 16), stride=(1, 16, 16))\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (blocks): ModuleList(\n",
            "      (0): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (neck): ConvTransformerTokensToEmbeddingNeck(\n",
            "    (fpn1): Sequential(\n",
            "      (0): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (1): Norm2d(\n",
            "        (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (2): GELU()\n",
            "      (3): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (fpn2): Sequential(\n",
            "      (0): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (1): Norm2d(\n",
            "        (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (2): GELU()\n",
            "      (3): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (decode_head): FCNHead(\n",
            "    input_transform=None, ignore_index=255, align_corners=False\n",
            "    (loss_decode): DiceLoss()\n",
            "    (conv_seg): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "    (convs): Sequential(\n",
            "      (0): ConvModule(\n",
            "        (conv): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "  (auxiliary_head): FCNHead(\n",
            "    input_transform=None, ignore_index=255, align_corners=False\n",
            "    (loss_decode): DiceLoss()\n",
            "    (conv_seg): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "    (convs): Sequential(\n",
            "      (0): ConvModule(\n",
            "        (conv): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvModule(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            ")\n",
            "2023-10-24 17:51:11,724 - mmseg - INFO - Loaded 327 images\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-24 17:51:16,148 - mmseg - INFO - Loaded 57 images\n",
            "2023-10-24 17:51:16,148 - mmseg - INFO - Start running, host: root@18cb8d36778d, work_dir: /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning\n",
            "2023-10-24 17:51:16,149 - mmseg - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) DistEvalHook                       \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) DistEvalHook                       \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "2023-10-24 17:51:16,149 - mmseg - INFO - workflow: [('train', 1)], max: 5 epochs\n",
            "2023-10-24 17:51:16,149 - mmseg - INFO - Checkpoints will be saved to /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning by HardDiskBackend.\n",
            "2023-10-24 17:51:16.648257: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-24 17:51:16.648317: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-24 17:51:16.648359: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-24 17:51:16.659094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-24 17:51:19.517411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-10-24 17:51:57,106 - mmcv - INFO - Reducer buckets have been rebuilt in this iteration.\n",
            "2023-10-24 17:52:19,847 - mmseg - INFO - Iter [20/405]\tlr: 1.570e-07, eta: 0:18:45, time: 2.924, data_time: 0.785, memory: 7887, decode.loss_dice: 0.5695, decode.acc_seg: 82.8543, aux.loss_dice: 0.5952, aux.acc_seg: 26.3315, loss: 1.1647\n",
            "2023-10-24 17:52:44,756 - mmseg - INFO - Iter [40/405]\tlr: 3.055e-07, eta: 0:12:41, time: 1.245, data_time: 0.002, memory: 7887, decode.loss_dice: 0.5692, decode.acc_seg: 84.0283, aux.loss_dice: 0.5955, aux.acc_seg: 25.3746, loss: 1.1647\n",
            "2023-10-24 17:53:10,548 - mmseg - INFO - Iter [60/405]\tlr: 4.369e-07, eta: 0:10:27, time: 1.290, data_time: 0.003, memory: 7887, decode.loss_dice: 0.5651, decode.acc_seg: 84.2977, aux.loss_dice: 0.5907, aux.acc_seg: 27.5305, loss: 1.1558\n",
            "2023-10-24 17:53:37,582 - mmseg - INFO - Iter [80/405]\tlr: 5.511e-07, eta: 0:09:13, time: 1.352, data_time: 0.002, memory: 7887, decode.loss_dice: 0.5657, decode.acc_seg: 86.0794, aux.loss_dice: 0.5906, aux.acc_seg: 29.7518, loss: 1.1562\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 1.1 task/s, elapsed: 54s, ETA:     0s\n",
            "\n",
            "2023-10-24 17:54:33,069 - mmseg - INFO - per class results:\n",
            "2023-10-24 17:54:33,070 - mmseg - INFO - \n",
            "+--------------+-------+-------+\n",
            "|    Class     |  IoU  |  Acc  |\n",
            "+--------------+-------+-------+\n",
            "| Not Well Pad | 89.48 | 90.23 |\n",
            "|   Well Pad   |  1.11 | 12.36 |\n",
            "+--------------+-------+-------+\n",
            "2023-10-24 17:54:33,070 - mmseg - INFO - Summary:\n",
            "2023-10-24 17:54:33,071 - mmseg - INFO - \n",
            "+-------+-------+------+\n",
            "|  aAcc |  mIoU | mAcc |\n",
            "+-------+-------+------+\n",
            "| 89.49 | 45.29 | 51.3 |\n",
            "+-------+-------+------+\n",
            "2023-10-24 17:54:39,304 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_1.pth.\n",
            "2023-10-24 17:54:39,305 - mmseg - INFO - Best mIoU is 0.4529 at 1 epoch.\n",
            "2023-10-24 17:54:39,305 - mmseg - INFO - Iter(val) [57]\taAcc: 0.8949, mIoU: 0.4529, mAcc: 0.5130, IoU.Not Well Pad: 0.8948, IoU.Well Pad: 0.0111, Acc.Not Well Pad: 0.9023, Acc.Well Pad: 0.1236\n",
            "2023-10-24 17:55:07,500 - mmseg - INFO - Iter [100/405]\tlr: 6.483e-07, eta: 0:08:25, time: 1.483, data_time: 0.127, memory: 9198, decode.loss_dice: 0.5630, decode.acc_seg: 88.8067, aux.loss_dice: 0.5877, aux.acc_seg: 32.7221, loss: 1.1506\n",
            "2023-10-24 17:55:34,099 - mmseg - INFO - Iter [120/405]\tlr: 7.283e-07, eta: 0:07:37, time: 1.329, data_time: 0.002, memory: 9198, decode.loss_dice: 0.5645, decode.acc_seg: 90.1685, aux.loss_dice: 0.5893, aux.acc_seg: 34.1018, loss: 1.1538\n",
            "2023-10-24 17:56:00,127 - mmseg - INFO - Iter [140/405]\tlr: 7.912e-07, eta: 0:06:53, time: 1.301, data_time: 0.002, memory: 9198, decode.loss_dice: 0.5638, decode.acc_seg: 91.9186, aux.loss_dice: 0.5875, aux.acc_seg: 38.0225, loss: 1.1513\n",
            "2023-10-24 17:56:26,448 - mmseg - INFO - Iter [160/405]\tlr: 8.370e-07, eta: 0:06:14, time: 1.316, data_time: 0.004, memory: 9198, decode.loss_dice: 0.5644, decode.acc_seg: 93.8259, aux.loss_dice: 0.5866, aux.acc_seg: 44.8568, loss: 1.1510\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 3.0 task/s, elapsed: 19s, ETA:     0s\n",
            "\n",
            "2023-10-24 17:56:48,041 - mmseg - INFO - per class results:\n",
            "2023-10-24 17:56:48,042 - mmseg - INFO - \n",
            "+--------------+-------+-------+\n",
            "|    Class     |  IoU  |  Acc  |\n",
            "+--------------+-------+-------+\n",
            "| Not Well Pad | 96.55 | 97.42 |\n",
            "|   Well Pad   |  1.86 |  6.84 |\n",
            "+--------------+-------+-------+\n",
            "2023-10-24 17:56:48,042 - mmseg - INFO - Summary:\n",
            "2023-10-24 17:56:48,042 - mmseg - INFO - \n",
            "+-------+-------+-------+\n",
            "|  aAcc |  mIoU |  mAcc |\n",
            "+-------+-------+-------+\n",
            "| 96.56 | 49.21 | 52.13 |\n",
            "+-------+-------+-------+\n",
            "2023-10-24 17:56:48,053 - mmseg - INFO - The previous best checkpoint /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning/best_mIoU_epoch_1.pth was removed\n",
            "2023-10-24 17:56:55,172 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_2.pth.\n",
            "2023-10-24 17:56:55,173 - mmseg - INFO - Best mIoU is 0.4921 at 2 epoch.\n",
            "2023-10-24 17:56:55,173 - mmseg - INFO - Iter(val) [57]\taAcc: 0.9656, mIoU: 0.4921, mAcc: 0.5213, IoU.Not Well Pad: 0.9655, IoU.Well Pad: 0.0186, Acc.Not Well Pad: 0.9742, Acc.Well Pad: 0.0684\n",
            "2023-10-24 17:57:21,165 - mmseg - INFO - Iter [180/405]\tlr: 8.657e-07, eta: 0:05:42, time: 1.442, data_time: 0.130, memory: 9198, decode.loss_dice: 0.5567, decode.acc_seg: 95.3863, aux.loss_dice: 0.5798, aux.acc_seg: 48.1106, loss: 1.1365\n",
            "2023-10-24 17:57:48,036 - mmseg - INFO - Iter [200/405]\tlr: 8.772e-07, eta: 0:05:08, time: 1.344, data_time: 0.002, memory: 9198, decode.loss_dice: 0.5565, decode.acc_seg: 96.0117, aux.loss_dice: 0.5781, aux.acc_seg: 53.9987, loss: 1.1346\n",
            "2023-10-24 17:58:14,315 - mmseg - INFO - Iter [220/405]\tlr: 8.717e-07, eta: 0:04:34, time: 1.314, data_time: 0.003, memory: 9198, decode.loss_dice: 0.5612, decode.acc_seg: 97.5496, aux.loss_dice: 0.5818, aux.acc_seg: 60.7861, loss: 1.1430\n",
            "2023-10-24 17:58:40,499 - mmseg - INFO - Iter [240/405]\tlr: 8.490e-07, eta: 0:04:02, time: 1.309, data_time: 0.002, memory: 9198, decode.loss_dice: 0.5596, decode.acc_seg: 97.8191, aux.loss_dice: 0.5797, aux.acc_seg: 65.4444, loss: 1.1393\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 3.0 task/s, elapsed: 19s, ETA:     0s\n",
            "\n",
            "2023-10-24 17:59:03,295 - mmseg - INFO - per class results:\n",
            "2023-10-24 17:59:03,295 - mmseg - INFO - \n",
            "+--------------+-------+-------+\n",
            "|    Class     |  IoU  |  Acc  |\n",
            "+--------------+-------+-------+\n",
            "| Not Well Pad | 98.69 | 99.61 |\n",
            "|   Well Pad   |  1.86 |  2.61 |\n",
            "+--------------+-------+-------+\n",
            "2023-10-24 17:59:03,296 - mmseg - INFO - Summary:\n",
            "2023-10-24 17:59:03,296 - mmseg - INFO - \n",
            "+-------+-------+-------+\n",
            "|  aAcc |  mIoU |  mAcc |\n",
            "+-------+-------+-------+\n",
            "| 98.69 | 50.27 | 51.11 |\n",
            "+-------+-------+-------+\n",
            "2023-10-24 17:59:03,307 - mmseg - INFO - The previous best checkpoint /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning/best_mIoU_epoch_2.pth was removed\n",
            "2023-10-24 17:59:17,680 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_3.pth.\n",
            "2023-10-24 17:59:17,681 - mmseg - INFO - Best mIoU is 0.5027 at 3 epoch.\n",
            "2023-10-24 17:59:17,681 - mmseg - INFO - Iter(val) [57]\taAcc: 0.9869, mIoU: 0.5027, mAcc: 0.5111, IoU.Not Well Pad: 0.9869, IoU.Well Pad: 0.0186, Acc.Not Well Pad: 0.9961, Acc.Well Pad: 0.0261\n",
            "2023-10-24 17:59:42,424 - mmseg - INFO - Iter [260/405]\tlr: 8.092e-07, eta: 0:03:33, time: 1.454, data_time: 0.140, memory: 9198, decode.loss_dice: 0.5545, decode.acc_seg: 98.2157, aux.loss_dice: 0.5760, aux.acc_seg: 67.8541, loss: 1.1305\n",
            "2023-10-24 18:00:09,681 - mmseg - INFO - Iter [280/405]\tlr: 7.523e-07, eta: 0:03:02, time: 1.363, data_time: 0.003, memory: 9198, decode.loss_dice: 0.5510, decode.acc_seg: 98.3862, aux.loss_dice: 0.5724, aux.acc_seg: 71.6050, loss: 1.1234\n",
            "2023-10-24 18:00:35,978 - mmseg - INFO - Iter [300/405]\tlr: 6.782e-07, eta: 0:02:32, time: 1.315, data_time: 0.002, memory: 9198, decode.loss_dice: 0.5521, decode.acc_seg: 98.5813, aux.loss_dice: 0.5710, aux.acc_seg: 78.2337, loss: 1.1230\n",
            "2023-10-24 18:01:01,962 - mmseg - INFO - Iter [320/405]\tlr: 5.871e-07, eta: 0:02:02, time: 1.299, data_time: 0.003, memory: 9198, decode.loss_dice: 0.5565, decode.acc_seg: 98.9650, aux.loss_dice: 0.5759, aux.acc_seg: 78.8725, loss: 1.1324\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 3.0 task/s, elapsed: 19s, ETA:     0s\n",
            "\n",
            "2023-10-24 18:01:25,999 - mmseg - INFO - per class results:\n",
            "2023-10-24 18:01:26,000 - mmseg - INFO - \n",
            "+--------------+-------+-------+\n",
            "|    Class     |  IoU  |  Acc  |\n",
            "+--------------+-------+-------+\n",
            "| Not Well Pad | 98.94 | 99.89 |\n",
            "|   Well Pad   |  0.93 |  1.04 |\n",
            "+--------------+-------+-------+\n",
            "2023-10-24 18:01:26,000 - mmseg - INFO - Summary:\n",
            "2023-10-24 18:01:26,001 - mmseg - INFO - \n",
            "+-------+-------+-------+\n",
            "|  aAcc |  mIoU |  mAcc |\n",
            "+-------+-------+-------+\n",
            "| 98.94 | 49.94 | 50.46 |\n",
            "+-------+-------+-------+\n",
            "2023-10-24 18:01:26,001 - mmseg - INFO - Iter(val) [57]\taAcc: 0.9894, mIoU: 0.4994, mAcc: 0.5046, IoU.Not Well Pad: 0.9894, IoU.Well Pad: 0.0093, Acc.Not Well Pad: 0.9989, Acc.Well Pad: 0.0104\n",
            "2023-10-24 18:01:49,352 - mmseg - INFO - Iter [340/405]\tlr: 4.788e-07, eta: 0:01:33, time: 1.457, data_time: 0.137, memory: 9198, decode.loss_dice: 0.5522, decode.acc_seg: 98.8645, aux.loss_dice: 0.5714, aux.acc_seg: 82.2331, loss: 1.1236\n",
            "2023-10-24 18:02:15,795 - mmseg - INFO - Iter [360/405]\tlr: 3.534e-07, eta: 0:01:04, time: 1.322, data_time: 0.003, memory: 9198, decode.loss_dice: 0.5490, decode.acc_seg: 98.7200, aux.loss_dice: 0.5678, aux.acc_seg: 84.1039, loss: 1.1168\n",
            "2023-10-24 18:02:42,228 - mmseg - INFO - Iter [380/405]\tlr: 2.109e-07, eta: 0:00:35, time: 1.322, data_time: 0.004, memory: 9198, decode.loss_dice: 0.5506, decode.acc_seg: 98.9110, aux.loss_dice: 0.5691, aux.acc_seg: 85.4412, loss: 1.1197\n",
            "2023-10-24 18:03:08,591 - mmseg - INFO - Iter [400/405]\tlr: 5.123e-08, eta: 0:00:07, time: 1.318, data_time: 0.004, memory: 9198, decode.loss_dice: 0.5488, decode.acc_seg: 98.8460, aux.loss_dice: 0.5682, aux.acc_seg: 84.5001, loss: 1.1170\n",
            "2023-10-24 18:03:15,156 - mmseg - INFO - Saving checkpoint at 5 epochs\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 3.0 task/s, elapsed: 19s, ETA:     0s\n",
            "\n",
            "2023-10-24 18:03:44,571 - mmseg - INFO - per class results:\n",
            "2023-10-24 18:03:44,572 - mmseg - INFO - \n",
            "+--------------+------+-------+\n",
            "|    Class     | IoU  |  Acc  |\n",
            "+--------------+------+-------+\n",
            "| Not Well Pad | 99.0 | 99.94 |\n",
            "|   Well Pad   | 0.63 |  0.67 |\n",
            "+--------------+------+-------+\n",
            "2023-10-24 18:03:44,572 - mmseg - INFO - Summary:\n",
            "2023-10-24 18:03:44,573 - mmseg - INFO - \n",
            "+------+-------+-------+\n",
            "| aAcc |  mIoU |  mAcc |\n",
            "+------+-------+-------+\n",
            "| 99.0 | 49.81 | 50.31 |\n",
            "+------+-------+-------+\n",
            "2023-10-24 18:03:44,573 - mmseg - INFO - Iter(val) [57]\taAcc: 0.9900, mIoU: 0.4981, mAcc: 0.5031, IoU.Not Well Pad: 0.9900, IoU.Well Pad: 0.0063, Acc.Not Well Pad: 0.9994, Acc.Well Pad: 0.0067\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mim\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mim/commands/train.py\", line 100, in cli\n",
            "    is_success, msg = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mim/commands/train.py\", line 261, in train\n",
            "    ret = subprocess.check_call(\n",
            "  File \"/usr/lib/python3.10/subprocess.py\", line 369, in check_call\n",
            "    raise CalledProcessError(retcode, cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'torch.distributed.launch', '--nproc_per_node=1', '--master_port=24023', '/usr/local/lib/python3.10/dist-packages/mmseg/.mim/tools/train.py', '/content/gdrive/MyDrive/HLS foundation guide/hls_config.py', '--launcher', 'pytorch']' died with <Signals.SIGSEGV: 11>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing\n",
        "Evaluating the model can be done with the command below. Here we must define the model checkpoint to evaluate."
      ],
      "metadata": {
        "id": "nsbXDh0JyJ3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_checkpoint = \"/content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning/epoch_5.pth\"\n",
        "path_to_checkpoint = f\"'{path_to_checkpoint}'\"\n",
        "\n",
        "!mim test mmsegmentation {config_file_path} --checkpoint {path_to_checkpoint} --eval \"mIoU\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMbfGcme_X-g",
        "outputId": "2e0bee3b-81d3-48fa-e978-fa374fdc9308"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing command is /usr/bin/python3 /usr/local/lib/python3.10/dist-packages/mmseg/.mim/tools/test.py /content/gdrive/MyDrive/HLS foundation guide/hls_config.py /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning/epoch_5.pth --launcher none --eval mIoU. \n",
            "2023-10-24 18:10:14,298 - mmseg - INFO - Multi-processing start method is `None`\n",
            "2023-10-24 18:10:14,302 - mmseg - INFO - OpenCV num_threads is `2\n",
            "2023-10-24 18:10:14,306 - mmseg - INFO - Loaded 57 images\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "load from /content/gdrive/MyDrive/HLS Foundation Model/Prithvi_100M.pt\n",
            "load checkpoint from local path: /content/gdrive/MyDrive/HLS Foundation Model/Prithvi_100M.pt\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for pos_embed: copying a param with shape torch.Size([1, 589, 768]) from checkpoint, the shape in current model is torch.Size([1, 197, 768]).\n",
            "unexpected key in source state_dict: mask_token, decoder_pos_embed, decoder_embed.weight, decoder_embed.bias, decoder_blocks.0.norm1.weight, decoder_blocks.0.norm1.bias, decoder_blocks.0.attn.qkv.weight, decoder_blocks.0.attn.qkv.bias, decoder_blocks.0.attn.proj.weight, decoder_blocks.0.attn.proj.bias, decoder_blocks.0.norm2.weight, decoder_blocks.0.norm2.bias, decoder_blocks.0.mlp.fc1.weight, decoder_blocks.0.mlp.fc1.bias, decoder_blocks.0.mlp.fc2.weight, decoder_blocks.0.mlp.fc2.bias, decoder_blocks.1.norm1.weight, decoder_blocks.1.norm1.bias, decoder_blocks.1.attn.qkv.weight, decoder_blocks.1.attn.qkv.bias, decoder_blocks.1.attn.proj.weight, decoder_blocks.1.attn.proj.bias, decoder_blocks.1.norm2.weight, decoder_blocks.1.norm2.bias, decoder_blocks.1.mlp.fc1.weight, decoder_blocks.1.mlp.fc1.bias, decoder_blocks.1.mlp.fc2.weight, decoder_blocks.1.mlp.fc2.bias, decoder_blocks.2.norm1.weight, decoder_blocks.2.norm1.bias, decoder_blocks.2.attn.qkv.weight, decoder_blocks.2.attn.qkv.bias, decoder_blocks.2.attn.proj.weight, decoder_blocks.2.attn.proj.bias, decoder_blocks.2.norm2.weight, decoder_blocks.2.norm2.bias, decoder_blocks.2.mlp.fc1.weight, decoder_blocks.2.mlp.fc1.bias, decoder_blocks.2.mlp.fc2.weight, decoder_blocks.2.mlp.fc2.bias, decoder_blocks.3.norm1.weight, decoder_blocks.3.norm1.bias, decoder_blocks.3.attn.qkv.weight, decoder_blocks.3.attn.qkv.bias, decoder_blocks.3.attn.proj.weight, decoder_blocks.3.attn.proj.bias, decoder_blocks.3.norm2.weight, decoder_blocks.3.norm2.bias, decoder_blocks.3.mlp.fc1.weight, decoder_blocks.3.mlp.fc1.bias, decoder_blocks.3.mlp.fc2.weight, decoder_blocks.3.mlp.fc2.bias, decoder_blocks.4.norm1.weight, decoder_blocks.4.norm1.bias, decoder_blocks.4.attn.qkv.weight, decoder_blocks.4.attn.qkv.bias, decoder_blocks.4.attn.proj.weight, decoder_blocks.4.attn.proj.bias, decoder_blocks.4.norm2.weight, decoder_blocks.4.norm2.bias, decoder_blocks.4.mlp.fc1.weight, decoder_blocks.4.mlp.fc1.bias, decoder_blocks.4.mlp.fc2.weight, decoder_blocks.4.mlp.fc2.bias, decoder_blocks.5.norm1.weight, decoder_blocks.5.norm1.bias, decoder_blocks.5.attn.qkv.weight, decoder_blocks.5.attn.qkv.bias, decoder_blocks.5.attn.proj.weight, decoder_blocks.5.attn.proj.bias, decoder_blocks.5.norm2.weight, decoder_blocks.5.norm2.bias, decoder_blocks.5.mlp.fc1.weight, decoder_blocks.5.mlp.fc1.bias, decoder_blocks.5.mlp.fc2.weight, decoder_blocks.5.mlp.fc2.bias, decoder_blocks.6.norm1.weight, decoder_blocks.6.norm1.bias, decoder_blocks.6.attn.qkv.weight, decoder_blocks.6.attn.qkv.bias, decoder_blocks.6.attn.proj.weight, decoder_blocks.6.attn.proj.bias, decoder_blocks.6.norm2.weight, decoder_blocks.6.norm2.bias, decoder_blocks.6.mlp.fc1.weight, decoder_blocks.6.mlp.fc1.bias, decoder_blocks.6.mlp.fc2.weight, decoder_blocks.6.mlp.fc2.bias, decoder_blocks.7.norm1.weight, decoder_blocks.7.norm1.bias, decoder_blocks.7.attn.qkv.weight, decoder_blocks.7.attn.qkv.bias, decoder_blocks.7.attn.proj.weight, decoder_blocks.7.attn.proj.bias, decoder_blocks.7.norm2.weight, decoder_blocks.7.norm2.bias, decoder_blocks.7.mlp.fc1.weight, decoder_blocks.7.mlp.fc1.bias, decoder_blocks.7.mlp.fc2.weight, decoder_blocks.7.mlp.fc2.bias, decoder_norm.weight, decoder_norm.bias, decoder_pred.weight, decoder_pred.bias\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/mmseg/models/decode_heads/decode_head.py:104: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "load checkpoint from local path: /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning/epoch_5.pth\n",
            "/usr/local/lib/python3.10/dist-packages/mmseg/.mim/tools/test.py:264: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n",
            "  warnings.warn(\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 57/57, 2.3 task/s, elapsed: 25s, ETA:     0sper class results:\n",
            "\n",
            "+--------------+------+-------+\n",
            "|    Class     | IoU  |  Acc  |\n",
            "+--------------+------+-------+\n",
            "| Not Well Pad | 99.0 | 99.94 |\n",
            "|   Well Pad   | 0.63 |  0.67 |\n",
            "+--------------+------+-------+\n",
            "Summary:\n",
            "\n",
            "+------+-------+-------+\n",
            "| aAcc |  mIoU |  mAcc |\n",
            "+------+-------+-------+\n",
            "| 99.0 | 49.81 | 50.31 |\n",
            "+------+-------+-------+\n",
            "\u001b[32mTesting finished successfully.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Folder location where the input tiff is stored\n",
        "input_tiff_path = \"/content/gdrive/MyDrive/GeoTile Examples/examples/\"\n",
        "\n",
        "#Folder location where inference output will be stored\n",
        "output_folder_path = \"/content/\"\n",
        "\n",
        "input_tiff_path = f\"'{input_tiff_path}'\"\n",
        "output_folder_path = f\"'{output_folder_path}'\""
      ],
      "metadata": {
        "id": "-qXP9x58vdwE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferences can be generated easily from a GeoTiff of any size. Ensure that the input Geotiff has the same preproccessing / normalization as the training dataset."
      ],
      "metadata": {
        "id": "lpL4gQ7zv13B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_inference.py -config {config_file_path} -ckpt {path_to_checkpoint} -input {input_tiff_path} -output {output_folder_path} -input_type tif -bands 0 1 2 3 4 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWNIxRouihTb",
        "outputId": "b2740b4c-27ad-4be7-ea4b-9f5884390ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmseg/models/decode_heads/decode_head.py:104: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "load checkpoint from local path: /content/gdrive/MyDrive/HLS foundation guide/HLS_wellpad_finetuning/epoch_5.pth\n",
            "Identified images to predict on: 1\n",
            "Working on Image 0\n",
            "Running inference...\n"
          ]
        }
      ]
    }
  ]
}